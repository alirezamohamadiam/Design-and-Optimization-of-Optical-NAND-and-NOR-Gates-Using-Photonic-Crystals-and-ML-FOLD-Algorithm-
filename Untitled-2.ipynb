{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 0.031925526997707024\n",
      "Random Forest MSE: 0.04831769200000004\n",
      "Gradient Boosting MSE: 0.022358337586655355\n",
      "Support Vector Regression MSE: 0.09430770865896448\n",
      "K-Nearest Neighbors MSE: 0.13040739999999998\n",
      "AdaBoost Regressor MSE: 0.061412534722222224\n",
      "XGBoost Regressor MSE: 0.03683723025589658\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load data from CSV file\n",
    "data = pd.read_csv('Book2.csv')\n",
    "\n",
    "# Create interaction features\n",
    "data['R_phi2_interaction'] = data['R'] * data['phi 2']\n",
    "\n",
    "# Select features and target variables\n",
    "X = data[['R', 'phi 2', 'R_phi2_interaction']].values\n",
    "y = data[['A=B=0', 'A=0  B=1', 'A=1  B=0', 'A=B=1']].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the models (wrap models with MultiOutputRegressor)\n",
    "models = {\n",
    "    'Linear Regression': MultiOutputRegressor(LinearRegression()),\n",
    "    'Random Forest': MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "    'Gradient Boosting': MultiOutputRegressor(GradientBoostingRegressor(n_estimators=100, random_state=42)),\n",
    "    'Support Vector Regression': MultiOutputRegressor(SVR()),\n",
    "    'K-Nearest Neighbors': MultiOutputRegressor(KNeighborsRegressor()),\n",
    "    'AdaBoost Regressor': MultiOutputRegressor(AdaBoostRegressor(n_estimators=100, random_state=42)),\n",
    "    'XGBoost Regressor': MultiOutputRegressor(xgb.XGBRegressor(n_estimators=100, random_state=42))\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model using Mean Squared Error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    results[model_name] = mse\n",
    "\n",
    "# Print the results\n",
    "for model_name, mse in results.items():\n",
    "    print(f'{model_name} MSE: {mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y: (25, 4)\n",
      "Mean Absolute Error (MAE) for Scenario 0: 0.0\n",
      "Mean Absolute Error (MAE) for Scenario 1: 5.716013040601986e-06\n",
      "Mean Absolute Error (MAE) for Scenario 2: 4.1223291073810845e-06\n",
      "Mean Absolute Error (MAE) for Scenario 3: 0.2596359995208488\n",
      "\n",
      "Top 7 sorted by optimize_R_XOR:\n",
      "      R  phi2  GB_preds_AB_0  GB_preds_A_1B_0  GB_preds_A_0B_1  GB_preds_AB_1  \\\n",
      "15  0.4   -90            0.0         0.530002         0.699999       0.031725   \n",
      "10  0.3   -90            0.0         0.400005         0.799996       0.090402   \n",
      "1   0.5   -90            0.0         0.749996         0.550002       0.200270   \n",
      "5   0.2   -45            0.0         0.350007         0.819995       0.141639   \n",
      "16  0.3   -45            0.0         0.400005         0.799996       0.202827   \n",
      "23  0.2   -90            0.0         0.350007         0.819995       0.198205   \n",
      "11  0.6   -90            0.0         0.999990         0.350008       0.399008   \n",
      "\n",
      "    optimize_R_XOR  \n",
      "15       11.694437  \n",
      "10        3.539766  \n",
      "1         2.059721  \n",
      "5         2.026305  \n",
      "16        1.577711  \n",
      "23        1.448019  \n",
      "11        0.877185  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# Load data from CSV file\n",
    "data = pd.read_csv('Book2.csv')\n",
    "\n",
    "# Create interaction features\n",
    "data['R_phi2_interaction'] = data['R'] * data['phi 2']\n",
    "\n",
    "# Select features and target variables\n",
    "X = data[['R', 'phi 2', 'R_phi2_interaction']].values\n",
    "y = data[['A=B=0', 'A=0  B=1', 'A=1  B=0', 'A=B=1']].values\n",
    "\n",
    "# Check shape of y (should be 2D)\n",
    "print(f\"Shape of y: {y.shape}\")\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train separate Gradient Boosting models for each target variable using MultiOutputRegressor\n",
    "gb_model = MultiOutputRegressor(GradientBoostingRegressor(n_estimators=100, random_state=42))\n",
    "\n",
    "# Fit the model to the training data\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "gb_test_predictions = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Gradient Boosting models\n",
    "mae_scenario = {}\n",
    "for i in range(4):\n",
    "    mae_scenario[f'Scenario {i}'] = mean_absolute_error(y_test[:, i], gb_test_predictions[:, i])\n",
    "    print(f\"Mean Absolute Error (MAE) for Scenario {i}: {mae_scenario[f'Scenario {i}']}\")\n",
    "\n",
    "# Function to predict new values\n",
    "def predict_new_values(R, phi2):\n",
    "    new_data = np.array([[R, phi2, R * phi2]])\n",
    "    new_data = scaler.transform(new_data)\n",
    "    predictions = gb_model.predict(new_data)\n",
    "    return predictions[0]\n",
    "\n",
    "# Define the input values for R and phi2\n",
    "R_values = [0.2, 0.2, 0.2, 0.2, 0.2, \n",
    "    0.3, 0.3, 0.3, 0.3, 0.3,\n",
    "    0.4, 0.4, 0.4, 0.4, 0.4, \n",
    "    0.5, 0.5, 0.5, 0.5, 0.5, \n",
    "    0.6, 0.6, 0.6, 0.6, 0.6]\n",
    "phi2_values = [0, 45, 90, -45, -90, \n",
    "    0, 45, 90, -45, -90, \n",
    "    0, 45, 90, -45, -90, \n",
    "    0, 45, 90, -45, -90, \n",
    "    0, 45, 90, -45, -90]\n",
    "\n",
    "# Generate unique combinations of R and phi2\n",
    "unique_pairs = list(set(zip(R_values, phi2_values)))\n",
    "\n",
    "# Predict for each unique combination of R and phi2\n",
    "results_dict = {}\n",
    "predictions = {'A=B=0': [], 'A=0  B=1': [], 'A=1  B=0': [], 'A=B=1': []}\n",
    "for R, phi2 in unique_pairs:\n",
    "    pred = predict_new_values(R, phi2)\n",
    "    results_dict[(R, phi2)] = pred\n",
    "    predictions['A=B=0'].append(pred[0])\n",
    "    predictions['A=0  B=1'].append(pred[1])\n",
    "    predictions['A=1  B=0'].append(pred[2])\n",
    "    predictions['A=B=1'].append(pred[3])\n",
    "\n",
    "# Convert predictions to numpy arrays for calculations\n",
    "predictions = {key: np.array(value) for key, value in predictions.items()}\n",
    "\n",
    "# Filter out predictions where 'A=B=0' or 'A=0  B=1' is above 1.1\n",
    "filter_mask = (predictions['A=B=0'] <= 1.1) & (predictions['A=0  B=1'] <= 1.05)\n",
    "filtered_predictions = {key: predictions[key][filter_mask] for key in predictions}\n",
    "\n",
    "# Calculate optimize_R formulas\n",
    "optimize_R_XOR = (1 * filtered_predictions['A=1  B=0']) * filtered_predictions['A=0  B=1'] / (1 * filtered_predictions['A=B=1'])\n",
    "\n",
    "# Prepare R and phi2 values for the DataFrame\n",
    "R_filtered = np.array([pair[0] for pair in unique_pairs])[filter_mask]\n",
    "phi2_filtered = np.array([pair[1] for pair in unique_pairs])[filter_mask]\n",
    "\n",
    "# Store the results in a DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'R': R_filtered,\n",
    "    'phi2': phi2_filtered,\n",
    "    'GB_preds_AB_0': filtered_predictions['A=B=0'],\n",
    "    'GB_preds_A_1B_0': filtered_predictions['A=0  B=1'],\n",
    "    'GB_preds_A_0B_1': filtered_predictions['A=1  B=0'],\n",
    "    'GB_preds_AB_1': filtered_predictions['A=B=1'],\n",
    "    'optimize_R_XOR': optimize_R_XOR,\n",
    "})\n",
    "\n",
    "# Sort by optimize_R_XOR in descending order\n",
    "sorted_XOR = results_df.sort_values(by='optimize_R_XOR', ascending=False).head(7)\n",
    "print(\"\\nTop 7 sorted by optimize_R_XOR:\")\n",
    "print(sorted_XOR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
